# CritterSupply Infrastructure Review - DevOps Assessment

**Review Date:** 2026-02-17  
**Reviewed By:** DevOps Engineer (AI Agent)  
**Review Scope:** Infrastructure readiness for Cycle 19-21 roadmap (Production Launch in 10 weeks)

---

## üéØ Executive Summary

**Sign-Off Decision:** ‚ö†Ô∏è **APPROVE WITH CONDITIONS**

**Overall Infrastructure Readiness:** 65% (Cycle 19 improvements will bring to 85%)

**Production Target:** End of Cycle 21 (10 weeks) is **ACHIEVABLE** with infrastructure investments outlined below.

---

## ‚úÖ What's Working (Infrastructure Strengths)

| Component | Status | Notes |
|-----------|--------|-------|
| **Docker Compose** | ‚úÖ Functional | Good for dev/CI, needs replacement for production |
| **GitHub Actions CI** | ‚úÖ Solid | NuGet caching, good practices, 10-min timeout |
| **PostgreSQL** | ‚úÖ Ready | Single instance sufficient for 1000 concurrent orders |
| **RabbitMQ** | ‚ö†Ô∏è Partial | Container exists, but durability not configured |
| **Test Infrastructure** | ‚úÖ Excellent | Alba + Testcontainers = industry best practice |

---

## üö® Critical Infrastructure Gaps (BLOCKING PRODUCTION)

### P0 Gap #1: RabbitMQ Durability Configuration ‚ùå BLOCKING

**Current State:**
```yaml
# docker-compose.yml
rabbitmq:
  image: "rabbitmq:management"
  ports:
    - "5672:5672"
    - "15672:15672"
```

**Problem:**
- ‚ùå No persistence configured - **ALL MESSAGES LOST ON RESTART**
- ‚ùå No durable queues defined
- ‚ùå No durable exchanges
- ‚ùå No virtual host configuration
- ‚ùå No access control (default `guest/guest`)

**Business Impact:**
- **Violates PO SLA:** 99.99% message durability requirement
- Customer orders lost during deployments/restarts
- Financial transactions incomplete (inventory reserved, payment never processed)

**Resolution (Cycle 19 - Week 1):**

```yaml
# docker-compose.yml - UPDATED
rabbitmq:
  container_name: crittersupply-rabbitmq
  image: "rabbitmq:3.12-management-alpine"  # Specific version for stability
  ports:
    - "5672:5672"
    - "15672:15672"
  environment:
    RABBITMQ_DEFAULT_USER: critter_admin
    RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-changeme}  # Inject via secrets
    RABBITMQ_DEFAULT_VHOST: /critter
  volumes:
    - rabbitmq_data:/var/lib/rabbitmq  # ‚ö†Ô∏è CRITICAL: Persist data
    - ./infrastructure/rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    - ./infrastructure/rabbitmq/definitions.json:/etc/rabbitmq/definitions.json:ro
  networks:
    - rmq_network
  profiles: [ all, ci ]
  healthcheck:
    test: ["CMD", "rabbitmq-diagnostics", "ping"]
    interval: 30s
    timeout: 10s
    retries: 5

volumes:
  rabbitmq_data:  # ‚ö†Ô∏è ADD THIS
```

**Required: `infrastructure/rabbitmq/rabbitmq.conf`**
```ini
# Durability settings (99.99% SLA requirement)
queue_master_locator = min-masters
disk_free_limit.absolute = 2GB

# Performance tuning for 1000 concurrent orders
channel_max = 256
heartbeat = 60

# Clustering (Cycle 21 - production HA)
# cluster_partition_handling = autoheal
```

**Required: `infrastructure/rabbitmq/definitions.json`**
```json
{
  "vhost": "/critter",
  "exchanges": [
    {
      "name": "storefront-notifications",
      "type": "fanout",
      "durable": true,
      "auto_delete": false
    }
  ],
  "queues": [
    {
      "name": "storefront-notifications",
      "vhost": "/critter",
      "durable": true,
      "auto_delete": false,
      "arguments": {
        "x-message-ttl": 3600000,
        "x-max-length": 100000,
        "x-overflow": "reject-publish"
      }
    }
  ],
  "bindings": [
    {
      "source": "storefront-notifications",
      "vhost": "/critter",
      "destination": "storefront-notifications",
      "destination_type": "queue",
      "routing_key": ""
    }
  ]
}
```

**Wolverine Configuration Update (ALL BCs):**
```csharp
// Program.cs - RabbitMQ durability
builder.Host.UseWolverine(opts =>
{
    opts.UseRabbitMq(rabbit =>
    {
        rabbit.HostName = "localhost";
        rabbit.VirtualHost = "/critter";
        rabbit.Username = "critter_admin";
        rabbit.Password = configuration["RabbitMQ:Password"];
        
        // ‚ö†Ô∏è CRITICAL: Enable durability
        rabbit.AutoProvision = true;
        rabbit.DeclareExchangesAndQueues = true;
        rabbit.DurableExchanges = true;
        rabbit.DurableQueues = true;
        
        // Dead-letter queue configuration (P0)
        rabbit.DeadLetterQueueing.Enabled = true;
        rabbit.DeadLetterQueueing.MaximumRedeliveryAttempts = 3;
    });
});
```

**Acceptance Criteria:**
- [ ] RabbitMQ container restart ‚Üí messages still in queue
- [ ] Host machine restart ‚Üí messages persisted
- [ ] Load test: 10,000 messages ‚Üí 0% loss
- [ ] Monitoring dashboard shows queue depth, message rate, consumer lag

---

### P0 Gap #2: Customer Isolation in SSE (GDPR Compliance) ‚ùå BLOCKING

**Current State:**
```csharp
// Customer.Experience/Services/EventBroadcaster.cs
public sealed class EventBroadcaster
{
    private readonly Channel<string> _channel = Channel.CreateUnbounded<string>();
    // ‚ö†Ô∏è PROBLEM: Single global channel - ALL customers see ALL events
}
```

**Business Impact:**
- **Privacy Violation:** Customer A sees Customer B's cart updates, orders, payments
- **GDPR Non-Compliance:** Cannot launch in EU without fix
- **PO Decision:** BLOCKING - Must fix or disable real-time features

**Resolution (Cycle 19 - Week 1):**

```csharp
// Customer.Experience/Services/EventBroadcaster.cs - UPDATED
public sealed class EventBroadcaster
{
    private readonly ConcurrentDictionary<Guid, Channel<string>> _customerChannels = new();
    
    public async Task BroadcastAsync(Guid customerId, string eventJson)
    {
        if (_customerChannels.TryGetValue(customerId, out var channel))
        {
            await channel.Writer.WriteAsync(eventJson);
        }
    }
    
    public IAsyncEnumerable<string> GetStreamAsync(Guid customerId, CancellationToken ct)
    {
        var channel = _customerChannels.GetOrAdd(customerId, 
            _ => Channel.CreateUnbounded<string>());
        return channel.Reader.ReadAllAsync(ct);
    }
    
    public void RemoveCustomer(Guid customerId)
    {
        if (_customerChannels.TryRemove(customerId, out var channel))
        {
            channel.Writer.Complete();
        }
    }
}
```

**Integration Event Handler Update:**
```csharp
// Customer.Experience/Handlers/ShoppingEventHandlers.cs
public static Task Handle(ItemAdded evt, EventBroadcaster broadcaster)
{
    // ‚ö†Ô∏è CRITICAL: Route to specific customer channel
    return broadcaster.BroadcastAsync(evt.CartId, evt.ToJson());
}
```

**Acceptance Criteria:**
- [ ] Customer A subscribes to SSE `/sse/cart/{cartId}` ‚Üí only sees their events
- [ ] Customer B simultaneously subscribes ‚Üí no cross-contamination
- [ ] Load test: 100 concurrent customers ‚Üí 0% event leakage
- [ ] Memory leak test: 1000 connect/disconnect cycles ‚Üí stable memory

---

### P0 Gap #3: No Dead-Letter Queue Monitoring ‚ùå BLOCKING

**Current State:**
- Dead-letter queues not configured (RabbitMQ defaults)
- No monitoring dashboard
- No alerting for failed messages

**Business Impact:**
- Failed payments/inventory reservations lost forever
- No visibility into error rates
- Cannot diagnose production issues

**Resolution (Cycle 19 - Week 2):**

**RabbitMQ DLQ Configuration:**
```json
// infrastructure/rabbitmq/definitions.json - ADD
{
  "queues": [
    {
      "name": "orders.dead-letter",
      "vhost": "/critter",
      "durable": true,
      "arguments": {
        "x-message-ttl": 86400000,
        "x-max-length": 10000
      }
    },
    {
      "name": "inventory.dead-letter",
      "vhost": "/critter",
      "durable": true
    },
    {
      "name": "payments.dead-letter",
      "vhost": "/critter",
      "durable": true
    }
  ]
}
```

**Monitoring Stack (Prometheus + Grafana):**
```yaml
# docker-compose.yml - ADD
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - monitoring_network
    profiles: [ all ]
  
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/grafana/dashboards:/etc/grafana/provisioning/dashboards
    networks:
      - monitoring_network
    profiles: [ all ]
  
  rabbitmq_exporter:
    image: kbudde/rabbitmq-exporter:latest
    environment:
      - RABBIT_URL=http://rabbitmq:15672
      - RABBIT_USER=critter_admin
      - RABBIT_PASSWORD=${RABBITMQ_PASSWORD:-changeme}
    ports:
      - "9419:9419"
    networks:
      - rmq_network
      - monitoring_network
    profiles: [ all ]

networks:
  monitoring_network:
    driver: bridge

volumes:
  prometheus_data:
  grafana_data:
```

**Prometheus Scrape Config:**
```yaml
# infrastructure/prometheus/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'rabbitmq'
    static_configs:
      - targets: ['rabbitmq_exporter:9419']
  
  - job_name: 'aspnetcore'
    static_configs:
      - targets:
        - 'orders-api:5231'
        - 'shopping-api:5232'
        - 'inventory-api:5233'
        - 'payments-api:5234'
        - 'fulfillment-api:5235'
```

**Grafana Alert Rules:**
```yaml
# infrastructure/grafana/alerts.yml
groups:
  - name: rabbitmq_alerts
    interval: 30s
    rules:
      - alert: DeadLetterQueueDepth
        expr: rabbitmq_queue_messages{queue=~".*dead-letter"} > 100
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Dead-letter queue depth > 100"
          description: "Queue {{ $labels.queue }} has {{ $value }} messages"
      
      - alert: SagaTimeout
        expr: order_saga_duration_seconds{state="PendingPayment"} > 300
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Order saga stuck for 5+ minutes"
```

**Acceptance Criteria:**
- [ ] Grafana dashboard shows: queue depth, message rate, DLQ depth, saga duration
- [ ] Alert fires when DLQ > 100 messages
- [ ] Alert fires when saga stuck > 5 minutes
- [ ] Historical metrics retained for 30 days

---

## ‚ö†Ô∏è High-Priority Gaps (MUST FIX FOR PRODUCTION)

### P1 Gap #1: No Load Testing Infrastructure

**Current State:**
- Single-threaded integration tests
- No concurrent user simulation
- No infrastructure to support 1000 concurrent orders

**PO Requirement:** Load test to 1000 concurrent orders before Cycle 21 launch

**Resolution (Cycle 20 - Week 1):**

**Load Testing Tool: k6**
```javascript
// infrastructure/load-tests/order-placement.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 },   // Ramp-up to 100 users
    { duration: '5m', target: 500 },   // Ramp-up to 500 users
    { duration: '5m', target: 1000 },  // Peak load: 1000 users
    { duration: '2m', target: 0 },     // Ramp-down
  ],
  thresholds: {
    http_req_duration: ['p(90)<5000', 'p(98)<10000'],  // PO SLA
    http_req_failed: ['rate<0.01'],  // <1% error rate
  },
};

export default function () {
  // 1. Create cart
  let cartRes = http.post('http://localhost:5232/api/carts/initialize');
  check(cartRes, { 'cart created': (r) => r.status === 201 });
  
  let cartId = cartRes.json('cartId');
  
  // 2. Add items
  http.post(`http://localhost:5232/api/carts/${cartId}/items`, JSON.stringify({
    sku: 'FERRET-FOOD-001',
    quantity: 2,
    unitPrice: 29.99
  }), { headers: { 'Content-Type': 'application/json' } });
  
  // 3. Initiate checkout
  let checkoutRes = http.post(`http://localhost:5232/api/carts/${cartId}/checkout`);
  let orderId = checkoutRes.json('orderId');
  
  // 4. Complete checkout
  http.post(`http://localhost:5231/api/orders/${orderId}/complete`, JSON.stringify({
    shippingAddressId: '3fa85f64-5717-4562-b3fc-2c963f66afa6',
    shippingMethodCode: 'STANDARD',
    paymentMethodType: 'CreditCard',
    paymentDetails: { last4: '4242' }
  }), { headers: { 'Content-Type': 'application/json' } });
  
  sleep(1);
}
```

**Run Load Test:**
```bash
# Install k6 (macOS)
brew install k6

# Run test
k6 run infrastructure/load-tests/order-placement.js --out json=results.json

# Analyze results
k6 inspect results.json
```

**Acceptance Criteria:**
- [ ] 1000 concurrent users placing orders
- [ ] 90% complete within 5 seconds (PO SLA)
- [ ] 98% complete within 10 seconds (PO SLA)
- [ ] <1% error rate
- [ ] No database deadlocks
- [ ] No message queue overload

---

### P1 Gap #2: No CI/CD Pipeline for Docker Images

**Current State:**
- GitHub Actions builds/tests code
- No Docker image builds
- No container registry
- No deployment automation

**Resolution (Cycle 19 - Week 3):**

```yaml
# .github/workflows/docker-build.yml
name: Docker Build & Push

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository_owner }}/crittersupply

jobs:
  build-matrix:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    strategy:
      matrix:
        service:
          - orders-api
          - shopping-api
          - inventory-api
          - payments-api
          - fulfillment-api
          - customer-identity-api
          - product-catalog-api
          - customer-experience
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/${{ matrix.service }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=sha
      
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: src/CritterSupply.${{ matrix.service }}/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
```

**Acceptance Criteria:**
- [ ] Every commit to `main` builds 8 Docker images
- [ ] Images pushed to GitHub Container Registry (ghcr.io)
- [ ] Images tagged with commit SHA + branch name
- [ ] Build uses layer caching (fast rebuilds)

---

### P1 Gap #3: No Secrets Management

**Current State:**
- Hardcoded passwords in `docker-compose.yml`
- No secrets rotation
- No production secrets strategy

**Resolution (Cycle 20):**

**Development (GitHub Actions Secrets):**
```yaml
# .github/workflows/dotnet.yml - ADD
- name: Start containers
  run: docker compose --profile ci up -d
  env:
    RABBITMQ_PASSWORD: ${{ secrets.RABBITMQ_PASSWORD }}
    POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
    GRAFANA_PASSWORD: ${{ secrets.GRAFANA_PASSWORD }}
```

**Production (Azure Key Vault / AWS Secrets Manager):**
```csharp
// Program.cs - ALL APIs
if (builder.Environment.IsProduction())
{
    var keyVaultUrl = builder.Configuration["KeyVault:Url"];
    builder.Configuration.AddAzureKeyVault(
        new Uri(keyVaultUrl),
        new DefaultAzureCredential());
}
```

**Acceptance Criteria:**
- [ ] No secrets in source control (git history audit)
- [ ] GitHub Actions uses GitHub Secrets
- [ ] Production uses Azure Key Vault / AWS Secrets Manager
- [ ] Secrets rotated every 90 days

---

## üìä Infrastructure Readiness by Cycle

### Cycle 19 (Weeks 1-3): Critical Infrastructure

| Component | Status | Owner | Completion Date |
|-----------|--------|-------|-----------------|
| RabbitMQ durability config | ‚ùå TODO | DevOps | Week 1 (3 days) |
| Customer-scoped SSE channels | ‚ùå TODO | Engineering | Week 1 (4 days) |
| DLQ configuration | ‚ùå TODO | DevOps | Week 2 (2 days) |
| Prometheus + Grafana setup | ‚ùå TODO | DevOps | Week 2 (3 days) |
| RabbitMQ monitoring dashboard | ‚ùå TODO | DevOps | Week 2 (2 days) |
| Docker image CI/CD | ‚ùå TODO | DevOps | Week 3 (3 days) |
| Secrets management (dev) | ‚ùå TODO | DevOps | Week 3 (2 days) |

**Risk Assessment:** HIGH (foundational changes)  
**Mitigation:** Daily standups, incremental rollout, rollback plan

---

### Cycle 20 (Weeks 4-5): Load Testing & Resilience

| Component | Status | Owner | Completion Date |
|-----------|--------|-------|-----------------|
| k6 load test suite | ‚ùå TODO | DevOps + QA | Week 4 (5 days) |
| Load test: 100 users | ‚ùå TODO | DevOps | Week 4 (1 day) |
| Load test: 500 users | ‚ùå TODO | DevOps | Week 5 (1 day) |
| Load test: 1000 users | ‚ùå TODO | DevOps | Week 5 (1 day) |
| Infrastructure tuning | ‚ùå TODO | DevOps | Week 5 (2 days) |

**Risk Assessment:** MEDIUM (performance unknowns)  
**Mitigation:** Incremental load increases, monitor metrics

---

### Cycle 21 (Weeks 6-10): Production Readiness

| Component | Status | Owner | Completion Date |
|-----------|--------|-------|-----------------|
| **Kubernetes cluster (AKS/EKS)** | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 6 (5 days) |
| Helm charts for all BCs | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 7 (5 days) |
| Ingress controller (NGINX) | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 7 (2 days) |
| TLS certificates (Let's Encrypt) | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 7 (1 day) |
| Managed PostgreSQL (Azure/AWS) | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 8 (3 days) |
| Managed RabbitMQ / CloudAMQP | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 8 (3 days) |
| Production monitoring (App Insights) | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 9 (3 days) |
| Backup/restore procedures | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 9 (2 days) |
| Runbooks for incidents | ‚ö†Ô∏è DECISION NEEDED | DevOps | Week 10 (3 days) |
| Production smoke tests | ‚ö†Ô∏è DECISION NEEDED | DevOps + QA | Week 10 (2 days) |

**Risk Assessment:** HIGH (production deployment)  
**Mitigation:** Staging environment testing, phased rollout

---

## ü§î Critical Questions for Stakeholders

### Question 1: Production Infrastructure - Kubernetes or Docker Compose?

**Current State:** Docker Compose (development-grade)

**Options:**

#### Option A: Stay on Docker Compose (NOT RECOMMENDED for production)
- ‚úÖ **Pros:** Simple, familiar, low ops overhead
- ‚ùå **Cons:** 
  - No horizontal scaling (cannot handle 1000 concurrent orders)
  - No self-healing (container crashes = manual restart)
  - No zero-downtime deployments
  - No load balancing
  - Single point of failure

**Recommendation:** ‚ùå **NOT SUITABLE FOR PRODUCTION**

---

#### Option B: Kubernetes (Azure AKS / AWS EKS / GKE) - RECOMMENDED
- ‚úÖ **Pros:** 
  - Auto-scaling (handle load spikes)
  - Self-healing (automatic restarts)
  - Rolling deployments (zero downtime)
  - Load balancing (distribute traffic)
  - Production-grade monitoring (Prometheus, Grafana)
- ‚ùå **Cons:** 
  - Learning curve (2-3 weeks initial setup)
  - Higher cost (~$200-500/month for cluster)
  - Complexity (requires DevOps expertise)

**Recommendation:** ‚úÖ **REQUIRED FOR PRODUCTION (Cycle 21)**

**Cost Estimate:**
- **Azure AKS:** ~$350/month (2 Standard_D2s_v3 nodes + managed PostgreSQL + managed RabbitMQ)
- **AWS EKS:** ~$400/month (2 t3.medium nodes + RDS PostgreSQL + Amazon MQ)
- **GCP GKE:** ~$300/month (2 n1-standard-2 nodes + Cloud SQL + Pub/Sub)

**Timeline:**
- **Week 6 (Cycle 21):** Provision Kubernetes cluster
- **Week 7:** Deploy staging environment
- **Week 8-9:** Load testing + tuning
- **Week 10:** Production deployment

---

#### Option C: Hybrid - Docker Compose + VM (COMPROMISE)
- Use Docker Compose on a single **large VM** (16 vCPU, 64GB RAM)
- Add NGINX load balancer in front
- Multiple container replicas (2x Orders, 2x Payments, etc.)
- ‚úÖ **Pros:** Simpler than Kubernetes, can handle 1000 users
- ‚ö†Ô∏è **Cons:** Still single point of failure, manual scaling

**Recommendation:** ‚ö†Ô∏è **ACCEPTABLE FOR INITIAL LAUNCH, migrate to K8s in Cycle 22**

**Cost Estimate:** ~$150-200/month (single Azure Standard_D16s_v3 VM)

---

**DECISION REQUIRED:** Which production infrastructure? (Deadline: End of Cycle 19)

---

### Question 2: RabbitMQ - Single Instance or Cluster?

**PO SLA:** 99.99% message durability

**Options:**

#### Option A: Single RabbitMQ Instance (Development)
- ‚úÖ **Pros:** Simple, low cost
- ‚ùå **Cons:** 
  - Single point of failure
  - **Does NOT meet 99.99% SLA** (allows ~1 hour downtime per year)
  - Message loss on container failure

**Recommendation:** ‚ùå **NOT SUITABLE FOR PRODUCTION**

---

#### Option B: RabbitMQ Cluster (3 nodes with quorum queues) - RECOMMENDED
```yaml
# docker-compose.yml - RabbitMQ Cluster
services:
  rabbitmq1:
    image: rabbitmq:3.12-management-alpine
    environment:
      RABBITMQ_ERLANG_COOKIE: 'secret_cluster_cookie'
      RABBITMQ_NODENAME: rabbit@rabbitmq1
    volumes:
      - rabbitmq1_data:/var/lib/rabbitmq
  
  rabbitmq2:
    image: rabbitmq:3.12-management-alpine
    environment:
      RABBITMQ_ERLANG_COOKIE: 'secret_cluster_cookie'
      RABBITMQ_NODENAME: rabbit@rabbitmq2
    volumes:
      - rabbitmq2_data:/var/lib/rabbitmq
  
  rabbitmq3:
    image: rabbitmq:3.12-management-alpine
    environment:
      RABBITMQ_ERLANG_COOKIE: 'secret_cluster_cookie'
      RABBITMQ_NODENAME: rabbit@rabbitmq3
    volumes:
      - rabbitmq3_data:/var/lib/rabbitmq
```

- ‚úÖ **Pros:** 
  - High availability (survives 1 node failure)
  - Meets 99.99% SLA
  - Quorum queues guarantee durability
- ‚ùå **Cons:** 
  - Complexity (clustering, split-brain handling)
  - 3x resource cost

**Recommendation:** ‚úÖ **REQUIRED FOR PRODUCTION (Cycle 21)**

---

#### Option C: Managed RabbitMQ (CloudAMQP / Azure Service Bus / AWS MQ) - BEST
- ‚úÖ **Pros:** 
  - Fully managed (automatic failover, backups, monitoring)
  - Meets 99.99% SLA out-of-the-box
  - Zero operational overhead
- ‚ùå **Cons:** 
  - Monthly cost (~$100-200 for production tier)

**Recommendation:** ‚úÖ **BEST OPTION FOR PRODUCTION**

**Cost Estimate:**
- **CloudAMQP (Tiger plan):** $199/month (HA, 99.99% SLA)
- **Azure Service Bus (Premium):** ~$150/month
- **AWS MQ (mq.m5.large):** ~$180/month

---

**DECISION REQUIRED:** RabbitMQ deployment strategy? (Deadline: End of Cycle 19)

---

### Question 3: Monitoring & Alerting - Self-Hosted or SaaS?

**Required Metrics:**
- Queue depth, message rate, DLQ depth
- Saga duration, timeout rate
- HTTP request duration (P90, P95, P99)
- Error rate by bounded context
- Database connection pool usage

**Options:**

#### Option A: Self-Hosted (Prometheus + Grafana) - RECOMMENDED FOR CYCLE 19-20
- ‚úÖ **Pros:** 
  - Free (no SaaS costs)
  - Full control over data retention
  - Already defined in Gap #3 resolution
- ‚ùå **Cons:** 
  - Operational overhead (maintain Prometheus/Grafana)
  - No built-in alerting to PagerDuty/Slack

**Recommendation:** ‚úÖ **Use for Cycle 19-20, migrate to SaaS in Cycle 21**

---

#### Option B: Application Insights (Azure) / CloudWatch (AWS) - RECOMMENDED FOR CYCLE 21
- ‚úÖ **Pros:** 
  - Fully managed (zero ops overhead)
  - Built-in alerting (email, SMS, PagerDuty)
  - APM (Application Performance Monitoring) for .NET
  - Distributed tracing (OpenTelemetry)
- ‚ùå **Cons:** 
  - Cost (~$50-150/month depending on volume)

**Recommendation:** ‚úÖ **MIGRATE IN CYCLE 21 (production deployment)**

**Cost Estimate:**
- **Azure Application Insights:** ~$100/month (5GB ingestion)
- **AWS CloudWatch:** ~$75/month (custom metrics + logs)
- **Datadog APM:** ~$200/month (8 hosts)

---

**DECISION REQUIRED:** Monitoring strategy? (Deadline: Cycle 19 Week 2)

---

### Question 4: Alerting - PagerDuty, Slack, or Email?

**Required Alerts:**
- Saga timeout (> 5 minutes) ‚Üí Alert engineering immediately
- DLQ depth > 100 ‚Üí Alert engineering within 15 minutes
- Error rate > 1% ‚Üí Alert engineering immediately
- API response time P95 > 10 seconds ‚Üí Alert engineering

**Options:**

#### Option A: Email Alerts (Free, Basic)
- ‚úÖ **Pros:** Free, easy to set up
- ‚ùå **Cons:** Easily ignored, no escalation, no on-call rotation

**Recommendation:** ‚ùå **NOT SUITABLE FOR PRODUCTION**

---

#### Option B: Slack Alerts (Free, Better)
```yaml
# Grafana Slack notification channel
apiVersion: 1
notifiers:
  - name: Slack
    type: slack
    uid: slack_alerts
    settings:
      url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
      recipient: '#critter-alerts'
      mentionUsers: '@devops-oncall'
```

- ‚úÖ **Pros:** 
  - Real-time notifications
  - Team visibility
  - Free (with existing Slack)
- ‚ùå **Cons:** 
  - No escalation policy
  - Not suitable for 24/7 on-call

**Recommendation:** ‚úÖ **USE FOR CYCLE 19-20 (development/staging)**

---

#### Option C: PagerDuty (Paid, Production-Grade) - RECOMMENDED
- ‚úÖ **Pros:** 
  - 24/7 on-call rotation
  - Escalation policies (alert manager ‚Üí escalate to director after 15 min)
  - Incident management (track MTTR, post-mortems)
  - Phone/SMS alerts
- ‚ùå **Cons:** 
  - Cost (~$25/user/month)

**Recommendation:** ‚úÖ **REQUIRED FOR PRODUCTION (Cycle 21)**

**Cost Estimate:** $25/user/month √ó 3 users (on-call rotation) = **$75/month**

---

**DECISION REQUIRED:** Alerting strategy? (Deadline: Cycle 20)

---

### Question 5: Deployment Strategy - Blue/Green, Canary, or Rolling?

**Context:** RabbitMQ migration in Cycle 19 requires zero-downtime deployment

**PO Requirement:** Zero downtime during deployments

**Options:**

#### Option A: Rolling Update (Kubernetes Default)
```yaml
# Deployment strategy
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
```

- ‚úÖ **Pros:** 
  - Simple, built-in Kubernetes feature
  - Zero downtime (old pods replaced gradually)
- ‚ö†Ô∏è **Cons:** 
  - Mixed versions running simultaneously (may cause message compatibility issues)

**Recommendation:** ‚ö†Ô∏è **USE FOR LOW-RISK DEPLOYMENTS (bug fixes, minor features)**

---

#### Option B: Blue/Green Deployment - RECOMMENDED FOR CYCLE 19
```yaml
# Blue environment (current production)
kubectl apply -f orders-api-blue.yaml

# Green environment (new version)
kubectl apply -f orders-api-green.yaml

# Test green environment
curl http://orders-api-green.internal/health

# Switch traffic (instant cutover)
kubectl patch service orders-api -p '{"spec":{"selector":{"version":"green"}}}'

# Rollback if needed (instant)
kubectl patch service orders-api -p '{"spec":{"selector":{"version":"blue"}}}'
```

- ‚úÖ **Pros:** 
  - Instant rollback (< 5 seconds)
  - No mixed versions
  - Full testing before cutover
- ‚ùå **Cons:** 
  - 2x resource usage (blue + green running simultaneously)

**Recommendation:** ‚úÖ **USE FOR CYCLE 19 RABBITMQ MIGRATION (high risk)**

---

#### Option C: Canary Deployment - RECOMMENDED FOR CYCLE 21
```yaml
# 90% traffic to stable version, 10% to canary
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: orders-api
spec:
  hosts:
  - orders-api
  http:
  - match:
    - headers:
        canary:
          exact: "true"
    route:
    - destination:
        host: orders-api
        subset: v2
  - route:
    - destination:
        host: orders-api
        subset: v1
      weight: 90
    - destination:
        host: orders-api
        subset: v2
      weight: 10
```

- ‚úÖ **Pros:** 
  - Gradual rollout (10% ‚Üí 50% ‚Üí 100%)
  - Early detection of issues (low blast radius)
  - Automatic rollback on error threshold
- ‚ùå **Cons:** 
  - Requires service mesh (Istio/Linkerd)
  - Complexity

**Recommendation:** ‚úÖ **USE FOR CYCLE 21 PRODUCTION DEPLOYMENTS**

---

**DECISION REQUIRED:** Deployment strategy per cycle? (Deadline: End of Cycle 19)

**Recommended Plan:**
- **Cycle 19:** Blue/Green (RabbitMQ migration = high risk)
- **Cycle 20:** Rolling updates (low-risk features)
- **Cycle 21:** Canary (production launch)

---

## üìã DevOps Deliverables by Cycle

### Cycle 19 Deliverables (Weeks 1-3)

**Week 1:**
- [ ] Update `docker-compose.yml` with RabbitMQ durability config
- [ ] Create `infrastructure/rabbitmq/rabbitmq.conf`
- [ ] Create `infrastructure/rabbitmq/definitions.json`
- [ ] Add health checks to all services
- [ ] Test: RabbitMQ restart ‚Üí messages persisted

**Week 2:**
- [ ] Add Prometheus + Grafana to `docker-compose.yml`
- [ ] Create Prometheus scrape configs
- [ ] Create Grafana dashboards (RabbitMQ, Saga duration, API metrics)
- [ ] Configure Slack alerting
- [ ] Test: Trigger DLQ alert, saga timeout alert

**Week 3:**
- [ ] Create `.github/workflows/docker-build.yml`
- [ ] Add Dockerfiles to all 8 bounded context APIs
- [ ] Set up GitHub Container Registry
- [ ] Add secrets management (GitHub Secrets)
- [ ] Test: Build all images, push to registry

---

### Cycle 20 Deliverables (Weeks 4-5)

**Week 4:**
- [ ] Create k6 load test suite (`infrastructure/load-tests/`)
- [ ] Test: 100 concurrent orders ‚Üí measure baseline performance
- [ ] Identify bottlenecks (database connections, queue depth, etc.)

**Week 5:**
- [ ] Test: 500 concurrent orders ‚Üí tune infrastructure
- [ ] Test: 1000 concurrent orders ‚Üí validate PO SLA (90% < 5s, 98% < 10s)
- [ ] Create load testing documentation (runbooks)

---

### Cycle 21 Deliverables (Weeks 6-10) - PENDING DECISIONS

**Week 6:**
- [ ] **DECISION:** Choose production infrastructure (K8s vs VM)
- [ ] Provision Kubernetes cluster (AKS/EKS) OR large VM
- [ ] Set up managed PostgreSQL (Azure Database / AWS RDS)
- [ ] Set up managed RabbitMQ (CloudAMQP / Azure Service Bus)

**Week 7:**
- [ ] Create Helm charts for all 8 BCs
- [ ] Deploy staging environment
- [ ] Configure Ingress controller (NGINX)
- [ ] Set up TLS certificates (Let's Encrypt)

**Week 8:**
- [ ] Migrate secrets to Azure Key Vault / AWS Secrets Manager
- [ ] Set up production monitoring (Application Insights / CloudWatch)
- [ ] Configure PagerDuty alerting (on-call rotation)
- [ ] Run smoke tests in staging

**Week 9:**
- [ ] Load test staging environment (1000 concurrent orders)
- [ ] Create backup/restore procedures (PostgreSQL, RabbitMQ)
- [ ] Create incident response runbooks (RabbitMQ down, DB failover, etc.)
- [ ] Security scan (Trivy, CodeQL, penetration testing)

**Week 10:**
- [ ] Production deployment (canary: 10% ‚Üí 50% ‚Üí 100%)
- [ ] Monitor metrics for 24 hours (error rate, latency, queue depth)
- [ ] Finalize production documentation
- [ ] **GO/NO-GO DECISION:** Production launch

---

## üí∞ Budget Estimate (Cycle 21 Production Infrastructure)

### Option 1: Kubernetes (Recommended)

| Component | Provider | Cost/Month | Notes |
|-----------|----------|------------|-------|
| **Kubernetes Cluster** | Azure AKS | $150 | 2 Standard_D2s_v3 nodes (2 vCPU, 8GB RAM each) |
| **Managed PostgreSQL** | Azure Database | $100 | General Purpose, 4 vCores, 100GB storage |
| **Managed RabbitMQ** | CloudAMQP (Tiger) | $199 | HA cluster, 99.99% SLA |
| **Application Insights** | Azure | $100 | 5GB ingestion, 90-day retention |
| **PagerDuty** | SaaS | $75 | 3 users (on-call rotation) |
| **DNS + SSL** | Azure DNS + Let's Encrypt | $5 | Custom domain |
| **Backup Storage** | Azure Blob Storage | $20 | PostgreSQL backups, 30-day retention |

**Total (Azure):** ~**$650/month** (~$7,800/year)

**Alternative: AWS EKS** ~$700/month  
**Alternative: GCP GKE** ~$550/month

---

### Option 2: Large VM (Compromise)

| Component | Provider | Cost/Month | Notes |
|-----------|----------|------------|-------|
| **Virtual Machine** | Azure Standard_D16s_v3 | $200 | 16 vCPU, 64GB RAM |
| **Managed PostgreSQL** | Azure Database | $100 | Same as above |
| **Managed RabbitMQ** | CloudAMQP (Tiger) | $199 | Same as above |
| **Application Insights** | Azure | $100 | Same as above |
| **PagerDuty** | SaaS | $75 | Same as above |
| **DNS + SSL** | Azure DNS + Let's Encrypt | $5 | Same as above |

**Total (VM):** ~**$680/month** (~$8,160/year)

**Note:** VM option has higher single-point-of-failure risk

---

**DECISION REQUIRED:** Infrastructure budget approval? (Deadline: End of Cycle 19)

---

## ‚ö†Ô∏è Risks & Mitigation Strategies

### Risk 1: Cycle 19 Timeline (2-3 weeks) Too Aggressive

**Risk Level:** HIGH

**Impact:** Infrastructure changes delayed ‚Üí blocks Cycle 20-21

**Mitigation:**
- **Add 1 week buffer** (make it 3-4 weeks instead of 2-3)
- Parallelize work streams:
  - Stream 1: RabbitMQ durability + DLQ (DevOps)
  - Stream 2: Customer isolation in SSE (Engineering)
  - Stream 3: Monitoring setup (DevOps)
- Daily standups to catch blockers early

---

### Risk 2: Load Testing Reveals Performance Issues

**Risk Level:** MEDIUM

**Impact:** Cannot meet PO SLA (90% < 5s, 98% < 10s)

**Mitigation:**
- **Optimize early:**
  - Add database connection pooling (Npgsql MaxPoolSize = 100)
  - Add HTTP client connection pooling
  - Tune RabbitMQ prefetch count
- **Identify bottlenecks:** Profile with BenchmarkDotNet, dotTrace
- **Horizontal scaling:** Add more API replicas (2x Orders, 2x Payments)

---

### Risk 3: No DevOps Engineer on Team

**Risk Level:** CRITICAL

**Impact:** Infrastructure work falls to software engineers (context switching, delays)

**Mitigation:**
- **Hire contract DevOps engineer** for Cycle 19-21 (3 months)
  - Cost: ~$10,000-15,000 (contract rate)
  - Alternative: Part-time consultant (20 hrs/week)
- **Or:** Principal Architect + Product Owner split DevOps tasks
  - Architect: Docker, Kubernetes, monitoring
  - PO: Vendor coordination (CloudAMQP, PagerDuty)

---

### Risk 4: Production Deployment Goes Wrong (Cycle 21)

**Risk Level:** HIGH

**Impact:** Customer-facing outage, revenue loss, reputation damage

**Mitigation:**
- **Blue/Green deployment** (instant rollback < 5 seconds)
- **Staging environment** (mirror production, test first)
- **Smoke tests** (automated health checks post-deployment)
- **Rollback plan:**
  1. Switch traffic back to blue environment
  2. Investigate issue in green environment (offline)
  3. Fix + redeploy
- **Go/No-Go criteria:**
  - [ ] All smoke tests passing (staging)
  - [ ] Load test results meet SLA (staging)
  - [ ] Zero critical security vulnerabilities (CodeQL, Trivy)
  - [ ] Runbooks complete (incident response)
  - [ ] On-call rotation confirmed (PagerDuty)

---

## ‚úÖ Approval Conditions (Sign-Off Requirements)

I **APPROVE WITH CONDITIONS** the Cycle 19-21 roadmap for production launch in 10 weeks.

**Conditions for Approval:**

### Cycle 19 (Critical Infrastructure - MUST COMPLETE)

1. ‚úÖ **RabbitMQ Durability Configuration**
   - docker-compose.yml updated with persistent volumes
   - rabbitmq.conf + definitions.json created
   - Wolverine DurableQueues = true (all BCs)
   - Test: Restart survives ‚Üí 0% message loss

2. ‚úÖ **Customer Isolation in SSE**
   - EventBroadcaster uses per-customer channels
   - Test: 100 concurrent customers ‚Üí 0% event leakage

3. ‚úÖ **Dead-Letter Queue + Monitoring**
   - DLQs configured (orders, inventory, payments, fulfillment)
   - Prometheus + Grafana deployed
   - Slack alerts configured (DLQ depth, saga timeout)

4. ‚úÖ **Docker Image CI/CD**
   - GitHub Actions builds + pushes images (8 BCs)
   - Images tagged with commit SHA

---

### Cycle 20 (Load Testing - MUST COMPLETE)

5. ‚úÖ **Load Testing Infrastructure**
   - k6 load tests written (cart ‚Üí checkout ‚Üí order)
   - Test: 1000 concurrent orders
   - Results meet PO SLA (90% < 5s, 98% < 10s)

---

### Cycle 21 (Production Deployment - PENDING DECISIONS)

6. ‚ö†Ô∏è **Production Infrastructure Decision**
   - **DECISION REQUIRED:** Kubernetes vs Large VM?
   - **DECISION REQUIRED:** Budget approval ($650-700/month)?
   - **DECISION REQUIRED:** Managed RabbitMQ provider (CloudAMQP vs Azure vs AWS)?
   - **Deadline:** End of Cycle 19 (Week 3)

7. ‚ö†Ô∏è **Monitoring & Alerting Decision**
   - **DECISION REQUIRED:** Self-hosted (Prometheus) vs SaaS (Application Insights)?
   - **DECISION REQUIRED:** PagerDuty vs Slack alerts?
   - **Deadline:** Cycle 20 (Week 5)

8. ‚ö†Ô∏è **Deployment Strategy Decision**
   - **DECISION REQUIRED:** Blue/Green (Cycle 19) vs Canary (Cycle 21)?
   - **Deadline:** End of Cycle 19 (Week 3)

---

## üìù Additional Requirements (Not Captured in Audit)

### 1. Disaster Recovery Plan (Cycle 21)

**Missing from audit:** Backup/restore procedures

**Required:**
- Automated PostgreSQL backups (daily, 30-day retention)
- Event stream replication (cross-region backup)
- RabbitMQ queue snapshots
- Restore testing (monthly drills)

**Acceptance Criteria:**
- [ ] RTO (Recovery Time Objective): < 4 hours
- [ ] RPO (Recovery Point Objective): < 1 hour (max data loss)
- [ ] Documented runbook: "How to restore from backup"

---

### 2. Security Scanning (Cycle 20)

**Missing from audit:** Container image vulnerability scanning

**Required:**
- Trivy scans (Docker images) on every build
- CodeQL scans (source code) on every PR
- Dependency scanning (NuGet packages) via Dependabot

**Acceptance Criteria:**
- [ ] Zero critical vulnerabilities in production images
- [ ] Security scan results in CI/CD pipeline
- [ ] Automated alerts for new CVEs

---

### 3. Network Security (Cycle 21)

**Missing from audit:** NetworkPolicies for BC isolation

**Required (if Kubernetes):**
```yaml
# NetworkPolicy: Orders BC can only talk to Inventory, Payments, Fulfillment
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: orders-api
spec:
  podSelector:
    matchLabels:
      app: orders-api
  policyTypes:
  - Egress
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: inventory-api
    - podSelector:
        matchLabels:
          app: payments-api
    - podSelector:
        matchLabels:
          app: fulfillment-api
```

**Acceptance Criteria:**
- [ ] Each BC has NetworkPolicy (deny-by-default)
- [ ] Test: Orders cannot call Shopping BC directly (blocked)

---

### 4. Rate Limiting (Cycle 22)

**Missing from audit:** API rate limiting to prevent abuse

**Required:**
- NGINX Ingress rate limiting (100 req/min per IP)
- ASP.NET Core rate limiting middleware
- Alert on rate limit violations (potential DDoS)

**Acceptance Criteria:**
- [ ] 429 Too Many Requests returned after threshold
- [ ] Authenticated users exempt from IP-based limits

---

## üéØ Final Recommendations

### Short-Term (Cycle 19 - Must Do)

1. ‚úÖ **Implement RabbitMQ durability** (P0 blocker)
2. ‚úÖ **Fix customer isolation in SSE** (P0 blocker, GDPR)
3. ‚úÖ **Set up monitoring + alerting** (Prometheus + Grafana + Slack)
4. ‚úÖ **Build Docker image CI/CD pipeline** (foundation for Cycle 21)
5. ‚ö†Ô∏è **Make infrastructure decisions** (K8s vs VM, budget approval)

---

### Medium-Term (Cycle 20 - Should Do)

6. ‚úÖ **Run load tests** (100 ‚Üí 500 ‚Üí 1000 concurrent orders)
7. ‚úÖ **Add security scanning** (Trivy, CodeQL, Dependabot)
8. ‚úÖ **Create runbooks** (incident response, backup/restore)

---

### Long-Term (Cycle 21 - Production Launch)

9. ‚úÖ **Deploy Kubernetes cluster** (or large VM as compromise)
10. ‚úÖ **Migrate to managed services** (PostgreSQL, RabbitMQ)
11. ‚úÖ **Set up production monitoring** (Application Insights / CloudWatch)
12. ‚úÖ **Configure PagerDuty** (on-call rotation)
13. ‚úÖ **Blue/Green or Canary deployment** (zero downtime)
14. ‚úÖ **Go/No-Go decision** (Week 10 - production readiness review)

---

## üìä Confidence Levels

| Aspect | Confidence | Notes |
|--------|------------|-------|
| **Cycle 19 completion** | 70% | Aggressive timeline, add 1 week buffer |
| **Meeting load test SLA** | 80% | Architecture is sound, may need tuning |
| **Cycle 21 on-time** | 60% | Depends on infrastructure decisions (pending) |
| **Production stability** | 75% | With proper monitoring + rollback plan |

---

## ‚úÖ DevOps Engineer Sign-Off

**Status:** ‚ö†Ô∏è **APPROVE WITH CONDITIONS**

**Conditions:**
1. Infrastructure decisions made by end of Cycle 19 (K8s vs VM, budget approval)
2. RabbitMQ durability + DLQ implemented (P0)
3. Customer isolation in SSE fixed (P0)
4. Monitoring + alerting set up (Prometheus + Grafana + Slack)
5. Load testing validates PO SLA (1000 concurrent orders, 90% < 5s)

**Production Launch:** ACHIEVABLE in 10 weeks (end of Cycle 21)

**Risk Assessment:** MEDIUM-HIGH (foundational infrastructure changes in Cycle 19)

**Mitigation:** Daily standups, incremental rollout, rollback plans, add 1 week buffer to Cycle 19

---

## üìû Next Actions

### Immediate (This Week)

1. **Schedule 60-minute infrastructure planning session**
   - Attendees: Principal Architect, Product Owner, DevOps Engineer
   - Agenda: Decide K8s vs VM, budget approval, RabbitMQ provider
   - Deadline: End of week

2. **Create Cycle 19 infrastructure tasks**
   - DevOps creates GitHub issues for all deliverables
   - Estimate effort (person-days per task)
   - Assign owners (DevOps vs Engineering split)

3. **Set up communication channels**
   - #critter-devops Slack channel (infrastructure updates)
   - #critter-alerts Slack channel (monitoring alerts)
   - Daily standup invite (Cycle 19 only)

---

### This Month (Cycle 19 Execution)

4. **Week 1:** RabbitMQ durability + customer isolation
5. **Week 2:** Monitoring + DLQ configuration
6. **Week 3:** Docker CI/CD + secrets management
7. **Week 4:** Load testing (Cycle 20 kickoff)

---

## üéì Documentation Updates Needed

After Cycle 19 completion:

1. **Update README.md**
   - Add "Infrastructure" section (Docker Compose, RabbitMQ, PostgreSQL)
   - Add "Monitoring" section (Prometheus, Grafana, Slack alerts)

2. **Update CONTEXTS.md**
   - Add "RabbitMQ Integration Status" table (update from audit)
   - Add "Deployment Strategy" section (blue/green, canary)

3. **Create RUNBOOKS.md**
   - RabbitMQ connection failures
   - Saga stuck in state
   - Database connection pool exhausted
   - Marten projection lag

4. **Create INFRASTRUCTURE.md** (NEW)
   - Docker Compose architecture
   - Kubernetes architecture (Cycle 21)
   - Monitoring stack (Prometheus, Grafana)
   - Secrets management (Azure Key Vault)
   - Backup/restore procedures

---

**Prepared By:** DevOps Engineer (AI Agent)  
**Review Date:** 2026-02-17  
**Status:** ‚ö†Ô∏è **APPROVED WITH CONDITIONS** - Ready for Infrastructure Planning Session  
**Next Milestone:** Cycle 19 Kickoff (RabbitMQ + Monitoring + CI/CD)

---

**Total Assessment Time:** 2 hours  
**Infrastructure Investment:** ~$650-700/month (Cycle 21 production)  
**DevOps Effort:** ~6 weeks (Cycle 19-21) or contract hire recommended  

**Production Launch Target:** End of Cycle 21 (10 weeks) ‚úÖ **ACHIEVABLE WITH CONDITIONS**
